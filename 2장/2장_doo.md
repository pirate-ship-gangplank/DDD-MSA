## 리액티브 선언 : 현대 애플리케이션이 갖춰야할 바람직한 속성들

소프트웨어 아키텍처 : 소프트웨어를 구성하는 요소와 그 구성요소 간의 관계를 정의한 것

### 리액티브 선언의 4가지 요소

1. **응답성** : 사용자에게 신뢰성 있는 응답을 빠르고 적절하게 제공하는 것
2. **탄력성** : 장애가 발생하거나 부분적으로 고장나더라도 시스템 전체가 고장나지 않고 빠르게 복구하는 능력
3. **유연성** : 시스템의 사용량에 변화가 있더라도 균일한 응답성을 제공하는 것. 
→ 시스템 사용량에 비례해서 자원을 늘리거나 줄이는 능력을 말한다.
4. **메시지 기반** : 비동기 메시지 전달을 통해 위치 투명성, 느슨한 결합, 논블록킹 통신을 지향하는 것

- 리액티브 시스템이 반드시 갖춰야 할 공통적인 특성은 바로 **아키텍처 유연성**이다. 
→ 시스템 자체가 변화와 확장에 언제든지 대응할 수 있는 것이 중요하다.
- **아키텍처 유연성**은 시스템 **구성요소 간의 관계들이 느슨하게 결합**되어 있어 언제든지 대체되거나 확장될 수 있다.
- 특히 **메시지 기반** 특성은 마이크로 서비스 간의 **의존성을 줄이는 중요한 특성**이 된다. (약한 결합)

## 강 결합에서 느슨한 결합의 아키텍처로의 변화

이전엔 아키텍처의 구성요소들을 각 기업이나 특정 벤더의 제품에 전적으로 의존했기 때문에, 기업이나 벤더의 제품이 변경되면 그것에 의존하는 애플리케이션의 많은 부분을 함께 변경해야했다.

- 신뢰성있고 안정성 있는 제품인 경우엔 품질이 보장된다는 장점이 있지만, **특정 기술에 락인(lock-in)**되어 쉽게 변경하거나 확장하지 못한다는 단점이 있다.
- 하지만 최근엔 **클라우드 환경**하에서 사용되는 오픈소스 또는 오픈소스를 기반으로 한 상용 제품들의 **품질이 높아지고, 서로 다른 오픈소스 제품 간에도 충분한 호환성**을 제공한다.
- 예전엔 검증된 기술이나 솔루션을 기반으로 기술을 직접 구현하는 폐쇄적인 방식이었지만, 최근엔 **필요한 영역에 적절한 솔루션을 선택하고 조합하는 개방적인 방식**으로 바뀌고 있다.

→ 각 레이어 별로 솔루션을 선택하고 이를 조합하여 사용하는 방식으로 **각 아키텍처 간의 강 결합을 줄이고, 느슨한 결합으로 변경하여 대체와 확장에 유리**하게 되었다.

## 마이크로서비스의 외부 아키텍처와 내부 아키텍처

**외부 아키텍처** : 애플리케이션 영역, 플랫폼 영역, 인프라 영역에 있는 구송요소 및 그것들의 관계를 정의하는 것

- 외부 아키텍처는 마이크로서비스가 운영되는 환경을 정의한다.

**내부 아키텍처** : 비즈니스가 실행되는 각 마이크로 서비스의 내부구조를 정의하는 것

- 마이크로서비스가 제공하는 API, 비즈니스 로직, 이벤트 발행, 데이터 저장 처리 등을 어떻게 구조화할지에 대한 내용

# MSA 구성요소 및 MSA 패턴

1. **인프라 구성요소** : 마이크로서비스를 지탱하는 하부구조 인프라를 구축하는 데 필요한 구성요소
2. **플랫폼 패턴** : 인프라 위에서 마이크로서비스의 운영과 관리를 지원하는 플랫폼 차원의 패턴
3. **애플리케이션 패턴** : 마이크로서비스 애플리케이션을 구성하는 데 필요한 패턴

# 1. 인프라 구성요소

**인프라** : 엔터프라이즈 IT 환경을 운영하고 관리하는 데 필요한 근간이 되는 하드웨어, 소프트웨어, 네트워킹 구성, 운영체제, 데이터 저장소 등을 모두 포괄한다.

→ 클라우드 환경에서는 이러한 **인프라 구성요소가 가상화되어 제공**된다.

### 퍼블릭 클라우드와 베어 메탈, 프라이빗 클라우드 환경

서비스를 만들기 위해서 먼저 맨 하부의 시스템의 기반이 되는 인프라를 구축해야한다.

여기서 고민은 **'기존의 물리적인 베어 메탈 장비를 구매해서 구축할 것인지, 아니면 가상화 환경을 선택해서 이용할지'**이다. → **베어 메탈**은 어떤 소프트웨어도 담지 않은 하드웨어 서버 제품군 자체를 의미한다.

- 사실 마이크로서비스는 어떠한 환경에서도 유연하도록 구성돼야 하므로 특정 인프라를 고집하진 않는다.
- 다만, 가상화 장치 없이 베어 메탈 장비로 마이크로서비스 애플리케이션을 구동한다면 **마이크로서비스마다 베어메탈 장비를 구축**해야하고, 인프라의 **유연한 확장 및 축소를 기대하기 힘든 무모한 작업**이 될 것이다.

    → 따라서 **가상 인프라 환경을 검토할 필요**가 있으며, MSA 시스템을 위한 **베어 메탈을 고려한다면 그것은 베어 메탈에 별도의 프라이빗 클라우드 환경을 구축하는 것**을 의미한다.

### VM과 컨테이너

가상 인프라 환경을 활용하기로 선택했다면 이제는 **가상머신 제품**과 **컨테이너 기반 제품** 중 하나를 선택해야 한다.

- **가상 머신** : '하이퍼바이저'라는 소프트웨어를 이용해 **하나의 시스템에서 여러 개의 운영체제를 사용**하는 기술이다.
- **컨테이너** : 하이퍼바이저 없이 **컨테이너 엔진**을 사용해 **가상의 격리된 공간을 생성**한다.

둘의 **차이점은 게스트 OS의 유무**이다. 게스트 OS를 사용하면 **운영체제 패치 설치나 관련 라이브러리 설치 같은 오버헤드가 지속적으로 발생**한다.

→ 따라서 **마이크로서비스 같은 작은 서비스**를 패키지하고 배포하기에는 **컨테이너 환경이 더 적합**하다.

**[ 도커 컨테이너의 장점 ]**

1. **이식성** : 어떠한 호스트 커널이나 플랫폼 버전에 상관없이 **도커만으로 실행할 수 있으면 사용 가능**하며 **동일하게 동작**한다.
2. **신속성** : **크기가 작고 가볍기** 때문에 **빠르게 배포** 가능하며, 문제 발생 시 수정할 필요 없이 새로 가동하면 된다.
3. **재사용성** : **동일한 환경을 재사용해서 쉽게 설정** 가능하기 때문에 개발, 테스트, 스테이징, 프로덕트 환경을 **동일한 환경으로 구축하기 쉽다**.

→ 마이크로서비스와 같이 **독립적으로 배포되고 수정되기 위한 환경**은 **가상머신보다는 컨테이너가 더 적절**하다. 왜냐하면 **마이크로서비스의 가변적이고 유연한 속성을 컨테이너가 더 쉽고 빠르게 지원**할 수 있기 때문이다.

### 컨테이너 오케스트레이션

**컨테이너 오케스트레이션** : 컨테이너를 관리하기 위한 기술. 컨테이너가 많이짐에 따라 컨테이너의 자동 배치 및 복제, 장애 복구, 확장 및 축소, 컨테이너 간 통신, 로드 밸런싱 등의 기능을 수행한다.

→ 도커 스웜, 아파치 메소스 등이 있는데, 최근엔 구글이 자사의 도커 컨테이너 관리 노하우를 리눅스 재단의 CNCF에 제공한 **쿠버네티스**가 큰 인기를 끌고있다. (K8s라고도 하는데, 8은 K와 s사이에 8자가 있기 때문이다.)

**[ 쿠버네티스의 주요 기능 ]**

- **자동화된 자원 배정** : 각 컨테이너가 필요로 하는 CPU와 메모리를 쿠버네티스에 요청하면 컨테이너를 노드에 맞춰 자동으로 배치한다.
- **셀프 치유** : 컨테이너의 이상 유무를 점검(health check)해서 실패한 경우 자동으로 교체하고 재스케줄링한다.
- **수평 확장** : 일정 CPU 및 메모리 사용량을 초과하면 자동으로 확장한다.

### 그 밖의 다양한 클라우드 인프라 서비스

모노리스 형태의 애플리케이션이라면, 가상 머신 클라우드 제품군인 AWS EC2, Azure VM을 사용할 수 있고, MSA 형태의 애플리케이션이라면, 컨티이너 기반인 AWS Beanstalk, ECS, Azure Web App, Google App Engine 등의 PaaS를 고려할 수 있다.

**[ 클라우드 서비스 유형 ]**

**Iaas (Infrastructure as a Service)** : 가상 머신, 스토리지, 네트워크 같은 인프라를 필요한 만큼 적시에 제공하는 서비스. 이러한 인프라를 이용해 개발 환경을 구성한 후 애플리케이션을 배포한다. 
→ 가상 서버, 가상 네트워크, 가상 스토리지 라고 생각하면 쉽다.
ex) AWS EC2, GCP Compute Engine, Azure VM

**Caas (Container  as a Service)** : 컨테이너 기반 가상화를 사용해 컨테이너를 업로드, 구성, 실행, 확장, 중지할 수 있는 서비스.

ex) 마이크로소프트의 Azure Kubernetes Service (AKS), 아마존의 Elastic Kubernetes Service (EKS), AWS ECS 등

**PaaS (Platform as a Service)** : 복잡함 없이 애플리케이션을 바로 개발, 실행, 관리할 수 있는 플랫폼 환경을 서비스 형태로 제공한 것. 
→ IaaS 위에 실제로 애플리케이션이 실행될 수 있는 미들웨어나 런타임까지 탑재된 환경이라고 생각하면 쉽다.

ex) Azure Web App, Google App Engine, Heroku, AWS Elastic Beanstalk 

# 2. 마이크로서비스 운영과 관리를 위한 플랫폼 패턴

인프라 구성을 마쳤다면, 선택한 인프라 환경 위에서 **애플리케이션을 운영하고 관리하는 환경을 구성하는 방법**을 생각해야 한다.

특히, **애플리케이션을 빌드하고 인프라에 배포할 수 있는 환경이 중요**한데, MSA를 구성하는 수많은 마이크로서비스를 하나씩 수동으로 빌드하고 배포하는 것은 매우 비효율적이고 어렵기 때문이다.

## 개발 지원 환경 : 데브옵스 인프라 구성

**데브옵스 환경** : 마이크로서비스를 **빌드하고 테스트한 뒤 배포**할 수 있게 도와주는 **개발 지원 환경**
→ 여기서는 조직의 의미가 아닌 빠르게 개발할 수 있도록하는 **빌드, 테스트, 배포를 위한 자동화 환경**을 말한다.

**[ 수동 배포 절차 ]**

1. 개발자는 개발 환경에서 애플리케이션을 완성하고, 컴파일하고 수동으로 테스트한 후 발생한 오류를 수정한 뒤 스테이징 환경에 배포한다.
2. 개발자는 운영 환경에 배포하기 전에 스테이징 환경에서 다시 수동으로 테스트한다. 그러다 오류가 발생하면 첫 환경인 개발 환경으로 돌아가 오류를 수정한 뒤 스테이징 환경에서 다시 테스트를 수행한다.
3. 이러한 과정이 모두 끝나면 승인 후 배포 담당자가 애플리케이션을 운영 환경에 배포한다.

→ 정말 많은 시간이 소요되는데, 여기에 필요한 것이 자동화된 **CI/CD (지속적 통합 및 배포)**이다.

**[ 자동 빌드 및 배포 절차 ]**

1. 개발자들이 작성한 소스코드와 테스트한 테스트 코드를 형상관리 시스템에 push 한다.
2. 빌드 도구에서 형상관리 시스템의 코드를 pull하여 통합한 다음, 자동으로 빌드하고 테스트 코드를 실행해 테스트를 수행한다.
3. 테스트 수행 결과를 리포트 문서로 기록하고, 빌드된 소스코드를 스테이징 환경에 자동으로 배포한다.
4. 테스터가 스테이징 환경에서 테스트를 수행하거나, 빌드 및 테스트 결과를 개발자가 확인하여 문제가 있으면 소스코드를 수정한다.

→ 수동 배포와의 차이점은 실행 환경에 반영하기 위해서 승인 및 배포 담장자의 허가를 받은 후 배포를 수동으로 진행한다는 것이다. CI/CD(지속적 배포)는 모든 영역을 자동화하였다.

## 빌드/배포 파이프라인 설계

**빌드/배포 파이프라인** : 빌드 및 배포되는 과정 동안 수행해야 할 태스크가 정의된 것

- 클라우드 환경이 대중화되면서, IaC(Infrastructure as Code)를 이용해서 인프라 구성을 마치 프로그래밍하는 것처럼 다룰 수 있게 되었다.
→ 코드이기 때문에 재사용할 수 있고, 쉽게 공유가 가능하다.

MSA의 경우 위처럼 각 마이크로서비스별로 레포지토리를 가지고 있어야하고, 그렇기 때문에 각각 별도의 빌드/배포 파이프라인을 구축하여 사용해야한다.

---

## 마이크로서비스 생태계와 운영관리 요소의 탄생

넷플릭스는 DVD 사업에서 스트리밍 사업으로 이전하면서 서비스를 모노리스 형태로 운영하고 있었는데, 스트리밍 DB의 스토리지가 손실되는 대규모 장애를 겪게 된다. 이를 계기로 넷플릭스는 모노리스에서 마이크로서비스 기반의 시스템으로 전환하는 작업을 시도했고, 이는 마이크로서비스 생태계에 큰 변화를 준다.

**마이크로서비스로 전환하면서 겪은 문제**도 있는데, 다음과 같은 문제들이 있었다.

- 한 서비스에서 발생한 장애가 다른 서비스로 전파
- 여러 서비스에 분산된 로그를 관리해야 하는 불편함
- 서비스 하나가 동작하지 않아 시스템의 일부 기능이 동작하지 않아도 그것을 알지 못하고 장애가 방치되는 문제

그러면서 넷플릭스는 이러한 문제의 **해결책으로 다양한 서비스와 도구를 개발하고, 이를 오픈소스로 공개**하는데 이것이 **넷플릭스 OSS**이다.

ex) 라우팅을 위한 Zuul, 로드밸런싱을 위한 Ribbon, 모니터링을 위한 Hystrix, 서비스 등록을 위한 Eureka 등

## 스프링 클라우드 : 스프링부트 + 넷플릭스 OSS

스프링 진영에서 스프링부트 프레임워크에서 넷플릭스 OSS를 더 쉽게 쓸 수 있도록 **넷플릭스 OSS 모듈들을 스프링 프레임워크**로 감싸서 **스프링 클라우드(Spring Cloud)**를 만들었다.

**[ 마이크로서비스 형태의 서비스와 클라우드 서비스의 연계 흐름 ]**

1. 스프링 클라우드 서비스를 포함한 모든 마이크로서비스는 인프라에 종속되지 않도록 DB, 파일 등에 저장된 환경 설정 정보를 형상 관리 시스템에 연계된 'Config 서비스'에서 가져와 설정 정보를 주입한 후 클라우드 인프라의 개별 인스턴스로 로딩한다.
2. 로딩과 동시에 '서비스 레지스트리'에 자신의 서비스명과 클라우드 인프라부터 할당받은 물리 주소를 매핑해서 등록한다.
3. 클라이언트가 'API 게이트웨이'를 통해 마이크로서비스에 접근하고, 이때 API 게이트웨이는 적절한 라우팅 및 부하관리를 위한 로드 밸런싱을 수행한다.
4. 또한 API 게이트웨이에서 클라이언트가 마이크로서비스에 접근하기 위한 주소를 알기 위해 '서비스 레지스트리' 검색을 통해 서비스의 위치를 가져온다.
5. 동시에 API 게이트웨이는 클라이언트가 각 서비스에 접근할 수 있는 권한이 있는지 '권한 서비스'와 연계해 인증/인가 처리를 수행한다.
6. 이러한 모든 마이크로서비스 간의 호출 흐름은 '모니터링 서비스'와 '추적 서비스'에 의해 모니터링되고 추적된다.

→ 이러한 처리 흐름은 여러 개의 마이크로서비스로 시스템을 개발하면서 발생한 문제를 해결하기 위한 MSA 주요 아키텍처 패턴으로 자리잡았다.

### 서비스 레지스트리/서비스 디스커버리 패턴 : 다양한 서비스의 등록 및 탐색

**서비스 디스커버리 패턴 :** 프론트엔드 클라이언트가 **여러 개의 백엔드 마이크로서비스를 호출**하거나, 스케일 아웃을 통한 **인스턴스가 여러 개로 복제된 상황에서 부하를 분산**할 때 ****사용하는 패턴

- **라우팅** : 여러 개의 마이크로서비스를 호출하기 위해 최적 경로를 찾아주는 기능. ex) 넷플릭스 OSS의 Zuul
- **로드 밸런싱** : 적절한 부하 분산을 위한 기능. ex) 넷플릭스 OSS의 Ribbon

**[ 라우터, 서비스 레지스트리 패턴 ]**

라우터는 최적 경로를 탐색하기 위해 서비스 명칭에 해당하는 IP 주소를 알아야 한다. 이러한 라우팅 정보를 클라이언트가 가지고 있으면 클라우드 환경에서 동적으로 변경되는 백엔드의 유동 IP 정보를 매번 전송받아 변경해야하기 때문에 불편함이 있다. 따라서 제3의 공간에서 이러한 정보를 관리하는 것이 좋다.

→ 넷플릭스 OSS의 **Eureka(유레카)**가 백엔드 마이크로서비스 **서비스의 명칭과 유동적인 IP 정보를 매핑해서 보관하는 역할**을 한다. 그리고 이러한 패턴을 **서비스 레지스트리 패턴**이라 한다.

**[ 서비스 레지스트리, 디스커버리 흐름 ]**

1. 각 인스턴스가 로딩될 때 자신의 서비스 이름과 할당된 IP 주소를 레지스트리 서비스에 등록한다.
→ 다수의 인스턴스가 하나의 서비스 이름으로 등록될 때 다수의 IP 주소와 포트 정보가 매핑된다. 로드 밸런싱 서비스는 이 정보를 사용하여 부하를 분산한다.
2. 클라이언트가 해당 서비스명을 호출할 때 라우터가 레지스트리 서비스를 검색해 해당 서비스의 이름과 매핑된 IP 정보를 확인한 후 호출한다.
→ 이 레지스트리 서비스(유레카)는 모든 마이크로서비스의 인스턴스의 주소를 알고 있는 서비스 매핑 저장소가 된다.

즉, 클라이언트가 요청을 하면 라우터(Zuul)가 서비스 레지스트리(Eureka)에서 해당하는 마이크로서비스를 찾아서 전달한다. 이때 로드밸런서(Ribbon)는 부하를 여러 개의 인스턴스에 적절하게 분산하여 요청한다.

### API 게이트웨이 패턴 : 서비스 단일 진입점

**API 게이트웨이 패턴** : **여러 개의 서비스를 클라이언트가 호출**할 때 각각을 호출하면 매우 복잡하기 때문에 **단일 진입점을 만들어 효율성**을 높인 패턴

- 다른 유형의 클라이언트에게 **서로 다른 API 조합**을 제공할 수 있다.
→ 아예 외부 레거시 시스템과 단일 지점에서 API를 연계하는 용도로도 쓸 수 있다.
- 각 서비스에 필요한 **인증/인가** 기능을 한 번에 처리할 수 있다.
- 정상적으로 동작하던 **서비스에 문제**가 생겨 서비스 요청에 대한 응답 지연이 발생하면 **정상적인 다른 서비스로 요청 경로를 변경**할 수 있다.

**[ API 게이트웨이 기능 ]**

- 레지스트리 서비스와 연계한 **동적 라우팅 및 로드밸런싱**
- 권한 서비스와 연계한 **인증/인가 (보안)**
- 로그집계 서비스와 연계한 **로깅**
- **메트릭**. ex) 에러율, 평균/최고 지연시간, 호출 빈도 등
- 트레이싱 서비스와 연계한 **서비스 추적**. ex) 트래킹 id 기록
- 모니터링 서비스와 연계한 **장애 격리** (서킷 브레이커 패턴)

### BFF 패턴

**BFF 패턴** : API 게이트웨이 같은 **진입점을 하나로 두지 않고,** **프런트엔드의 유형에 따라 각각 두는 패턴**

- PC뿐 아니라 다양한 클라이언트를 위해서는 특화된 처리를 위한 API 조합이나 처리가 필요하다.
- 웹을 위한API 게이트웨이, 앱을 위한 API 게이트웨이를 각각 둬서 **각 클라이언트 종류에 최적화된 처리를 수행**할 수 있다.
- 각 프론트엔드에 대한 처리만 수행하는 BFF를 두고 이후에 통합적인 API 게이트웨이를 둬서 공통적인 인증/인가, 로깅 등의 처리를 하는 구조로도 둘 수 있다. 
ex) 웹 BFF, 앱 BFF 모두가 다시 하나의 API 게이트웨이를 본다.

### 외부 구성 저장소 패턴 : 환경 설정 정보 분리

**외부 구성 저장소 패턴** : 애플리케이션 **구성 정보 설정에 관련된 패턴**
ex) 데이터베이스 연결 정보, 파일 스토리지 정보 등

- **외부 저장소** : 각 마이크로 서비스의 외부 환경 설정 정보를 공통으로 저장하는 백업 저장소
- **Config 원칙** : 애플리케이션이 **배포되는 환경(develop, stage, production)이 매번 달라지기 때문**에 코드에서 사용하는 **환경 설정 정보는 코드와 완전히 분리되어 관리**해야 한다는 원칙
→ 클라우드 네이티브 애플리케이션을 만들기 위한 체크리스트 중 하나의 원칙
- 환경 설정 정보가 애플리케이션에 있으면 환경 설정 정보가 변경되면 애플리케이션 또한 변경돼야 하고, 변경 내용을 배포해야 한다.

**[ Spring Cloud Config ]**

- 스프링 클라우드 컨피그 (Spring Cloud Config)를 이용하면 **환경 정보를 코드에서 분리**하고 컨피그 서비스를 통해 **런타임시 주입**할 수 있다.
- 환경 정보는 Git 같은 별도의 형상관리 레포지토리에 보관하고, 컨피그 서비스는 **배포되는 환경에 따라 적절한 환경 정보를 형상관리 레포지토리에서 가져와 해당 서비스에 주입**한다.
- 쿠버네티스에서는 이러한 외부 구성 저장소 패턴을 **쿠버네티스 컨피그맵**으로 제공한다.

### 인증/인가 패턴

각 마이크로서비스가 모두 인증/인가를 구현하는 것은 비효율적이다. 따라서 아래와 같은 패턴을 사용한다.

1. **중앙 집중식 세션 관리**
- **공유 저장소에 세션을 저장**하고 **모든 서비스가 동일한 사용자 데이터**를 얻는 방식

기존 모노리스 방식에서 가장 많이 사용했던 방식은 서버 세션에 사용자의 로그인 정보 및 권한 정보를 저장하고, 이를 통한 인증/인가를 판단하는 것이다. 하지만, 마이크로서비스는 사용량에 따라 수시로 수평 확장할 수 있고 로드 밸런싱 처리가 되기 때문에 세션 데이터가 손실될 수 있다.
→ 질문 : 세션 저장소가 각 인스턴스마다 하나씩 가지고 있는 형태인가? 

따라서 마이크로 서비스는 각자의 서비스에 세션을 저장하지 않고 **공유 저장소에 세션을 저장**하고 **모든 서비스가 동일한 사용자 데이터**를 얻게 한다. 이때 저장소는 보통 레디스나 멤캐시드를 사용한다.

**2. 클라이언트 토큰**

세션은 중앙 서버에 저장되고 토큰은 사용자의 브라우저에 저장된다. 

토큰은 사용자의 신원 정보를 가지고 있고 서버로 요청을 보낼 때 전송되기 때문에 서버에서 인가 처리를 할 수 있다. **JWT**는 토큰 형식을 정의하고 암호화하며 **다양한 언어에 라이브러리를 제공하는 공개표준**이다.

 **[ 클라이언트 토큰 흐름 ]** 

1. 브라우저가 서버에 사용자명과 패스워드로 인증을 요청한다. (로그인)
2. 서버는 인증 후 사용자 정보의 인증/인가 정보를 포함한 토큰을 생성하고 브라우저로 전송한다.
3. 브라우저는 서버 리소스를 요청할 때 토큰을 함께 보낸다. 서버는 토큰 정보를 확인한 후 자원 접근을 허용한다.

**3. API 게이트웨이를 사용한 클라이언트 토큰** 

위의 **2번 과정과 비슷**하지만, **API 게이트웨이가 외부 요청의 입구로 추가된다는 차이점**이 있다.

- 인증/인가를 처리하기 위한 별도의 전담 서비스를 만들어서 다른 서비스의 인증/인가 처리를 위임할 수 있다.
→ 이러한 서비스를 **인증 서비스**라고 부른다.
- 인증 서비스를 별도로 구성하면, 다른 **각 마이크로서비스가 자체적으로 인증/인가를 처리하지 않고 각자의 비즈니스 로직에 집중**할 수 있다.

**[ API 게이트웨이 + 인증 서비스를 활용한 클라이언트 토큰 흐름 ]**

1. 클라이언트가 리소스 서비스(마이크로서비스)에 접근을 요청하면 API 게이트웨이는 인증 서비스에게 전달한다.
2. 인증 서비스는 해당 요청에 대한 인증/인가를 모두 마치면, 리소스에 접근 가능한 증명서인 액세스 토큰을 발급한다.
3. 클라이언트는 다시 액셋스 토큰을 활용해 접근을 요청한다.
4. 각 리소스 서비스는 들어온 요청이 액세스 토큰을 포함하고 있는지 판단해서 리소스에 대한 접근을 허용한다.
→ 질문: JWT를 바로 마이크로서비스로 전달하기 때문에 각 마이크로서비스는 토큰에 대한 검증 로직은 구현되어 있어야한다. 이것도 아예 인증 서비스에서 해주면 토큰 검증 로직도 각각 구현하지 않아도 되지 않나?
→ 이건 매 요청 시 인증 서비스를 거쳐야하는 성능의 문제 때문에 각 마이크로서비스가 그냥 토큰 검증 로직을 구현하는건가?

### 서킷 브레이커 패턴 : 장애 및 실패 처리

**서킷 브레이커 패턴** : **장애가 발생한 서비스를 격리해서 유연하게 처리**하는 패턴

전체 시스템에 문제가 없어보이지만, 특정 서비스에 접근하면 즉각 에러가 발생하지도 않고, **한참 동안 대기하는 상황**이 생긴다. 이러한 상황은 정상적인 서비스가 장애가 발생한 서비스에 의존한 상태로서, **장애가 다른 서비스로 전이된 상황**이다.

- 시스템 과부하나 특정 서비스에 장애가 생겼을 때 자연스럽게 **다른 정상적인 서비스로 요청 흐름이 변경**되어야 한다.
→ 질문 : 여기서 말하는 정상적인 서비스로의 요청은 동일 서비스의 다른 EP를 말하는건가?
- **서비스 상태를 실시간으로 관리해서 시각화하고 모니터링**하여 장애가 다른 서비스로 전이되지 않도록 해야 한다.
→ 특정 서비스 호출에 대한 연속 실패 횟수가 임곗값을 초과하면 서킷 브레이커가 작동하여 서비스를 호출하려는 모든 시도를 즉시 실패하게 만든다. 즉시 실패하게 만든 후에 **폴백 메서드**로 자연스럽게 처리한다. (장애가 발생한 서비스의 응답을 계속 기다리지 않음)
- 정상적인 A 서비스가 장애 상태의 B 서비스에 요청을 보냈을 때, A가 B를 계속 기다리는 것은 **동기(sync) 요청**을 보냈을 때이다.
- **폴백(fallback) 메서드**를 지정해 두면 **장애가 발생**했을 때 폴백 메서드가 **자연스럽게 처리**를 진행한다.
→ 질문 : 폴백 메서드는 문제가 발생할 수 있는 EP에 지정해두면 그 EP에 문제가 생겼을 때 다른 정상적인 서비스로 요청을 하지않고, 해당 EP선에서 처리하는 방식인가?

### 모니터링과 추적 패턴

**모니터링** : 스프링 클라우드에서는 **Hystrix(히스트릭스)**라는 라이브러리를 제공하고, 히스트릭스 라이브러리가 배포된 서비스를 모니터링할 수 있는 **Hystrix Dashboard**를 제공함으로써 **요청을 실시간으로 모니터링**할 수 있다.

**분산 트레이싱 서비스** : 모니터링과 함께 **각 서비스 트랜잭션의 호출을 추적**한다.
→ 트위터에서 공개한 **집킨(Zipkin)**이라는 오픈 소스 대시보드로 **분산된 서비스 간의 호출**이나 **지역 구간별 장애 포인트를 확인**할 수 있다.

### 중앙화된 로그 집계 패턴

마이크로서비스가 사용량에 따라 탄력적으로 변화하면서 언제든지 인스턴스가 생성/삭제되는 과정에서 로컬 로그가 초기화될 수 있다.

Twelve-Factor의 '로그(Logs) 원칙'을 보면 **로그를 이벤트 스트림으로 처리**하라고 한다.

- **서비스는 스트림의 전달이나 저장에 절대 관여하지 않아야** 한다.
→ 왜냐하면 로그를 전달 및 저장하는 메커니즘 자체가 특정 기술이나 인프라에 의존할 수밖에 없고, 이러한 메커니즘을 직접 마이크로서비스에서 구현한다면 유연성이 떨어지기 때문이다.

**[ ELK 스택 ]**

서비스에서 발생한 **이벤트 스트림 형태의 로그를 수집하고 살펴볼 도구**로 ELK 스택을 많이 사용한다.

- **Elasticsearch(분산형 검색/분석 엔진)** : 정형, 비정형, 위치 정보, 메트릭 등 원하는 방법으로 검색을 수행/결합 가능
- **Logstash (로그 집합기)** : 데이터 처리 파이프라인, 다양한 소스에서 동시에 데이터를 수집해 변환한 뒤 특정 보관소로 데이터를 보냄
- **Kibana (시각화)** : 히스토그램, 막대 그래프, 파이차트 등 표현.

각 서비스에 로그스태시가 설치되어 각 로그를 수집해서 레디스 저장소에 보낸다. 또 다른 서비스에서는 엘라스틱서치와 키바나로 로그 중앙 관리 저장소와 대시보드 서비스를 각각 구축한다.

마이크로서비스에서 보낸 로그가 중앙 레디스에 쌓이면 레디스에서 중앙 관리 저장소에 로그를 보내고, 이 로그 저장소에 엘라스틱서치 엔진이 로그를 인덱싱하고 해당 로그 정보가 키바나 대시보드를 통해 보여진다.

→ 중간에 레디스를 둔 이유는 마이크로서비스의 로그스태시가 바로 로그 저장소에 로그를 보낼 수 있지만 로그 스트림이 너무 몰리면 로그 저장소 서비스에도 성능 문제가 생기기 때문에 중간 저장소를 추가한 것이다.

---

## MSA 기술 변화 흐름

마이크로서비스 API 호출, 로깅, 인증/인가, 장애 전이 등의 문제를 넷플릭스 OSS나 스프링 클라우드를 이용해서 해결했다. 문제 상황이 발생할 때마다 상이한 기술로 해결하였다.

그런데 이 문제들의 해결책을 한꺼번에 제공하는 쿠버네티스, 오픈시프트과 같은 솔루션들이 있다.

그런데 최근 동향은 **쿠버네티스에 이스티오(Istio) 기술**을 덧붙여 사용하는 것이다.

### 서비스 메시 패턴

**서비스 메시 패턴** : 인프라 레이어로서 서비스 간의 통신을 처리하며, **MSA 문제 영역 해결**을 위한 기능을 비즈니스 로직과 분리해서 **네트워크 인프라 계층에서 수행**하는 패턴

- 기존엔 MSA의 문제를 해결하기위해 **여러 개의 서비스를 별도로 만들어야한다는 번거로움**이 있었다.
- 또한, **기능 구현에 집중해야하는 마이크로서비스**에서 MSA의 문제를 해결하기 위해 **스프링 클라우드와 관련된 라이브러리를 추가**해야 했다.
- 그리고 스프링 클라우드는 자바 언어를 기반으로 하기 때문에 **다른 언어로 폴리글랏하게 구현된 경우**에는 **스프링 클라우드를 아예 사용하지 못한다.**

### 이스티오 (Istio)

서비스 메시 패턴의 대표적 구현체이다.

- **애플리케이션이 배포되는 컨테이너에 완전히 격리**되어 별도의 컨테이너로 배포되는 **사이드카 패턴**이다.
- **사이드카(Sidecar) 패턴** : 모든 서비스 컨테이너에 추가로 사이드카 컨테이너가 배포되는 패턴. 
→ 각 서비스를 연계할 때 **한 서비스가 다른 서비스를 직접 호출하지 않고, 사이드카인 프록시를 통해 연계**해서 개발자가 별도의 작업 없이 관리 및 운영에 대한 서비스를 적용할 수 있다.
- 마이크로서비스마다 함께 배포되는 **사이드카 프록시에 운영관리를 위한 기능이 별도로 담기기** 때문에 **마이크로서비스는 순수 비즈니스 로직에 집중**할 수 있다.

**[ 이스티오 주요 기능 ]**

- **트래픽 관리** : 동적 라우팅, 로드 밸런싱
- **보안** : 보안 통신 채널(TLS), 인증/인가/암호화
- **관측성** : 메트릭, 분산 트레이싱, 로깅

**[ 스프링 클라우드/넷플릿스 OSS VS 이스티오 ]**

- **애플리케이션 코드의 변경이 거의 없다.**
→ 완전히 사이드카로 격리되며 yaml 파일과 같은 설정 파일에 의해 정의된다.
- **폴리글랏 애플리케이션도 지원**한다.
→ 이스티오는 인프라 레이어에서 MSA 문제를 해결하기 때문에, 자바 언어가 아니어도 지원 가능하다.
- 이스티오는 **쿠버네티스와 완전히 통합된 환경**을 제공한다.

---

# 3. 애플리케이션 패턴

실제로 개발자가 구현해야 할 애플리케이션 영역의 패턴

## UI 컴포지트 패턴 (마이크로 프런트엔드)

백엔드 마이크로서비스처럼 **기능별로 분리**하고 이를 **조합**하기 위한 프레임 형태의 부모 창을 통해 **각 프론트엔드를 조합해서 동작**하는 방식

- 하나의 **마이크로서비스 팀은 별도의 독립된 레포지토리**를 가지고 백엔드와 프론트엔드를 관리하는데, **모든 UI가 합쳐져있으면 독립적인 기능별 빌드 및 배포가 어렵다**.
- 메인 화면을 제공하는 **부모 창은 장애가 발생해도 사용자가 알아채지 못하게 화면 구성을 재배열**하는 역할을 수행한다.

## 마이크로서비스 통신 패턴

마이크로서비스 간의 통신 방식

### 동기 통신 방식

- 클라이언트에서 서버 측에 존재하는 마이크로서비스 **REST API를 호출할 때 사용되는 기본 통신 방법**
- 라우팅이나 로드밸런싱을 위한 **API** **게이트웨이**를 중간에 넣을 수 있다.

**[ 백엔드 마이크로서비스 간의 동기 통신 ]**

- 가장 기본적인 방식은 REST API 같은 동기 호출 방식이다.
→ **동기 방식 : 요청(request)하면 응답(response)가 오는 방식**
- 요청을 보내면 **응답이 올 때까지 기다리고**, 응답이 오지 않으면 **계속 기다리면서 재호출**한다.
- 동기 호출 방식은 **장애 전파**로 이어질 수 있고, **서비스 간의 의존성이 높은 방식**이다.
→ 각 서비스별로 비즈니스 기능 처리를 어렵게 한다.

### 비동기 통신 방식

**비동기 통신 방식** : **메세지 기반**의 **비동기 호출**이다.

- 동기 호출처럼 **응답을 기다리지 않고, 메세지를 보낸** 다음 바로 다음 일을 처리한다.
→ 기다리지않고 다른 작업을 처리하므로 더욱 **효율적**이다.
→ 보낸 결과를 기다려서 바로 받는 것이 아니므로 동기식처럼 **완결성을 보장할 수는 없다.**
- 마이크로서비스 간에 **느슨한 결합**을 유지할 수 있다.
→ 느슨한 결합으로 **확장성과 탄력성** 측면에서 이점이 있다.
- **메세지 브로커**(kafka, rabbit mq, sqs 등)를 사이에 두고 **각 서비스가 메세지를 생산/소비하는 방식**으로 동작한다. 
→ **비동기 통신 매커니즘 + 이벤트 기반의 아키텍처 = 이벤트 기반 마이크로서비스**

**[ 메세지 브로커 장점 ]**

- 서로 통신하는 서비스들이 물리적으로 동일한 시스템에 있을 필요가 없다.
- 서로 프로세스를 공유할 필요가 없다.
- 동일한 시간대에 동시에 동작하지 않아도 된다.
- 만약 메세지 브로커 자체에 부하가 많이 발생하면 메세지 브로커의 메세지 처리 규모를 확장할 수 있다. 
→ 클라우드 플랫폼 환경에서 높은 탄력성을 사용할 수 있다.

## 저장소 분리 패턴

모든 서비스가 하나의 저장소를 사용하지않고, **각 마이크로서비별로 저장소를 가지는 패턴**

**[ 기존 모노리스 구조의 문제 ]**

- 기존 모노리스 시스템은 저장소를 모듈별로 나누지않고 다른 모듈에서의 호출을 허용하는 구조였다.
- 비즈니스 처리 로직이 데이터베이스의 SQL 관련한 내용이 많아지게 된다.
→ 질문 : 다른 모듈의 데이터를 사용해야하기 때문인가
- 서로 다른 모듈의 데이터를 사용하면서 join 등을 하게 되고, 이는 각기 다른 모듈에 대한 의존성을 높인다.
- 모든 요청이 하나의 데이터베이스로 들어오기 때문에, 요청이 몰릴 때 서비스는 한가하고 여러 서비스에서 호출되는 **통합 데이터베이스만 바쁜 상황**이 된다.
→ 서비스에 대한 **스케일 아웃을 해도 데이터베이스는 여전히 바쁘므로**, 성능 상의 이슈를 해결하지 못한다.
- **폴리글랏하지 못하다**. → 다양한 형태의 저장소를 사용하지 못한다.

**[ 저장소 분리 패턴의 이점 ]**

- 각 마이크로서비스는 각자의 비즈니스를 처리하기 위한 데이터를 직접 소유한다.
- 다른 서비스에 직접 데이터를 노출하지 않고, 공개된 api를 통해서만 접근이 가능하다. (정보 은닉)
- 저장소가 격리되어있어 각 저장소를 자율적으로 선택할 수 있다. (폴리글랏)
- 데이터를 통한 변경의 영향도를 줄여 서비스를 독립적으로 만든다.

## 분산 트랜잭션 처리 패턴

마이크로서비스에서 서로의 api를 호출하면서 발생할 수 있는 **비즈니스 정합성 및 데이터 일관성을 보장하기 위한 패턴**이다.

### 2단계 커밋 - 전통적인 방식으로 비추천

**분산 트랜잭션에 포함되어 있는 모든 노드**가 **커밋(commit) 또는 롤백(rollback)**하는 방식이다.

- 각 서비스에 **잠금(lock in)**이 걸려 발생하는 성능 문제가 있어 **비효율적**이다.
- **각 서비스가 다른 인스턴스로 로딩**되기 때문에 **통제가 어렵다**.
- 서비스의 **각 저장소가 서로 다를 경우 문제**가 있으며, NoSQL의 경우엔 2단계 커밋을 아예 지원하지 않는다.
- 네트워크 장애 등으로 **특정 서비스의 트랜잭션이 처리되지 않을 경우** **트랜잭션에 묶인 서비스가 즉시 영향**을 받기도 한다.

### 사가(Saga) 패턴

**각 서비스의 로컬 트랜잭션을 순차적으로 처리하는 패턴**이다.

- 분산된 서비스를 하나의 트랜잭션으로 묶지 않고, **각 로컬 트랜잭션**과 **보상 트랜잭션**을 이용한다.

- 각 **로컬 트랜잭션은 자신의 데이터베이스를 업데이트**한 다음, 사가 내에 있는 다음 로컬 트랜잭션을 트리거하는 **메세지 또는 이벤트를 게시**해서 **데이터의 일관성**을 맞춘다.
→ 실패 시에도 마찬가지로 이벤트 기반으로 메세지를 발행하여 **보상 트랜잭션**에 대한 트리거를 할 수 있도록 한다.
- `보상 트랜잭션` : 어떤 서비스에서 **트랜잭션 처리에 실패**할 경우, 그 서비스의 **앞선 다른 서비스에서 처리된 트랜잭션을 되돌리게 하는 트랜잭션**이다.
- 보상 트랜잭션이라고 꼭 전 단계를 무조건 롤백시킬 필요는 없다. 단순한 조회 같은 로직은 롤백할 것이 없고, **데이터베이스에서 발생한 데이터 변경에 대해서만 롤백** 처리를 해주면 된다.

### 결과적 일관성

**결과적 일관성** : **데이터의 일관성이 실시간으로 맞지 않더라도** **어느 일정 시점이 되었을 때 일관성을 만족하는 것**

- 결과적 일관성은 **고가용성을 극대화**한다.
→ 메세지를 발행하는 이벤트 기반인 경우엔 **메세지 브로커**에 요청을 보내므로, **결제 서비스가 망가져도 주문 서비스의 주문 요청은 모두 저장이 가능**하다. (우선 주문을 많이 받아 놓는 것)
- 실시간성을 강조하면 다른 서비스의 응답이 올 때까지 기다려야할텐데, 그렇게 되면 **한 서비스에 문제가 생겼을 때 계속 해당 요청을 기다리면서 장애가 전파**될 수 있다.
→ 결제 장애가 발생해 결제 서비스를 이용하지 못하면 주문 서비스도 함께 먹통이 된다. (계속 기다리면서 주문 지연 발생)
- 모든 비즈니스들이 실시간 일관성을 요구하는 것은 아니다.

**[ 비동기 통신 (이벤트 기반) + 사가 패턴 적용 사례 ]**

1. 가주문이 생성되고 '가주문됨' 이벤트를 발행한다.
- 주문은 독립적인 로컬 트랜잭션이기 때문에 끊임없이 받을 수 있다.
- 주문이 몰릴 경우 주문 서비스만 확장해서 가용성을 높일 수 있다.
2. '가주문됨' 이벤트는 메세지 브로커에 비동기로 전송된다.
3. 결제 서비스는 발행된 '가주문됨' 이벤트를 확인하고 대금 결제 트랜잭션을 수행하고 '결제 처리됨' 이벤트를 발행한다.
4. 이메일 서비스는 '결제 처리됨' 이벤트를 확인하고 주문 결제 완료 이메일을 사용자에게 발송한다.
5. 주문 서비스는 '결제 처리됨' 이벤트를 확인하고 가주문으로 처리됐던 주문을 최종 승인한다. 그리고 '최종 주문 완료됨' 이벤트를 발행한다.
6. 이메일 서비스는 주문 서비스가 발행한 '최종 주문 완료됨' 이벤트를 확인해 최종적으로 주문이 완료됐다는 이메일을 사용자에게 발송한다.
7. 각 서비스는 각기 작업을 수행하다 오류가 발생하면 '실패 이벤트'를 발행해 다른 서비스가 비즈니스 정합성을 맞출 수 있게 한다.
8. 이때 별도로 메세지 큐에 쌓이는 이벤트들을 모니터링 서비스와 연계해 모니터링하고 추적해서 전체적인 비즈니스 정합성 여부를 관리자가 확인할 수도 있다.

## CQRS 패턴 - 읽기와 쓰기의 분리

**CQRS(Command Query Responsibility Segregation**) : `명령`과 `조회`의 **책임을 분리**하는 패턴

- 일반적으로 **데이터를 변경(CUD)하는 명령**과 **데이터를 조회하는 조회** 중에 **조회를 더 많이 사용**한다.
- 그런데 일반적으로 **한 저장소에 명령과 조회 로직을 모두 처리**하는 방식을 사용한다.
- **서비스 내에 변경과 조회가 모두** 있으면 **조회 요청이 증가함에 따라 명령에 대한 기능도 함께 확장**해야하기 때문에 **비효율적**이다.
→ 명령과 조회가 모두 있어서 늘어나는 건 '조회'이지만 조회를 위한 확장 과정에서 '명령'도 함께 늘어난다.

**[ 쓰기와 읽기의 분리 ]**

- 읽기 로직만 처리하는 **'조회 서비스'**와 쓰기 로직을 처리하는 **'명령 서비스'**를 분리할 수 있다.
→ 저장소는 같은 저장소를 사용한다.
- 아예 **물리적으로 저장소를 분리**하여 **조회 서비스와 명령 서비스가 각각 저장소를 가지는 형태**로 진화할 수도 있다.

**[ 예시 ]**

한 인스턴스가 요청을 20개 처리할 수 있다고 가정해본다. 조회 요청이 30개, 쓰기 요청이 5개 도착하면 쓰기 요청은 조회 요청 30개를 전부 처리하는 동안 대기해야한다.

- 스케일 아웃을 해서 인스턴스를 늘린다고 해도, 많은 조회 요청 때문에 쓰기 요청에 대한 처리가 늦는 것은 어쩔 수 없는 것이다.
- 만약 명령 서비스가 만들어진다면, 조회가 30개가 있어도 쓰기 요청 5개는 무조건 명령 서비스로 요청이 들어가서 바로 처리가 될 것이다.

결론 : CQRS는 쓰기 요청을 전용으로 처리할 수 있는 서비스를 만들어주는 것이다.

**[ CQRS + 이벤트 메세지 주도 아키텍처 ]**

- 좌측은 명령(CUD)에 대한 처리를 한다. 
→ 저장소로는 쓰기에 최적화된 관계형 데이터베이스를 사용하고, 프로그래밍 언어로는 자바를 사용한다.
- 우측은 조회(Read)에 대한 처리를 한다. (사용량이 많기 때문에 스케일 아웃을 하여 인스턴스를 증가시킨다)
→ 저장소로는 조회 성능이 높은 몽고디비나 엘라스틱서치와 같은 NoSQL을 사용하고, 프로그래밍 언어는 간단하게 구현 가능한 Node.js를 사용한다.

**[ 두 서비스 간의 데이터 정합성 문제 ]**

이 구조에서 발생할 수 있는 문제가 있는데, 이는 명령과 조회의 데이터베이스를 분리하면서 명령으로 변경된 데이터가 조회 측의 데이터베이스에는 반영되지 않는다는 것이다.

이때 **데이터 일관성** 유지를 위해 필요한 것이 **이벤트 주도 아키텍처**이다.

- **명령 서비스**는 저장소에 데이터를 쓰면서 **저장한 내역이 담긴 이벤트를 발생시켜 메세지 브로커에 전달**한다.
- **조회 서비스**는 **메세지 브로커를 구독**하고 있다가 **이벤트 데이터를 가져와 데이터를 최신 상태로 동기화**한다.

## API 조합과 CQRS

### API 조합

**API 조합** : 여러 개의 마이크로서비스를 연계해서 로직을 처리해야하는 경우, **각 기능을 제공하는 마이크로서비스를 조합하는 상위 마이크로서비스를 만들어 조합된 기능을 제공**하는 방법

- **상위 서비스가 하위 서비스에 의존**하게 된다.
→ 하위 서비스 중 하나라도 API를 변경하면 상위 서비스는 그에 따라 변경될 수밖에 없다.
- 또한, **하위 서비스의 실패가 상위 서비스에 영향**을 준다.

⇒ 하위 서비스에 대한 의존성을 줄이기 위한 방법이 필요하다.

### CQRS

1. 주문 이력 서비스가 독자적인 저장소를 갖고, 주문 이력의 세세한 원천 정보를 보유하고 있는 다른 각각의 마이크로서비스도 각자의 저장소를 가진다.
2. 원천 정보를 보유하고 있는 각 마이크로서비스는 자신의 서비스 정보가 변경되는 시점에 변경 내역을 각자의 변경 이벤트로 발행한다.
3. 주문 이력 마이크로서비스는 이 이벤트들을 구독하고 있다가, 서비스의 저장소에 기록하여 다른 서비스의 데이터와 일관성을 맞추고 서비스의 주문 이력 조회 기능으로 제공한다.

이러면 **다른 원천 서비스에 장애**가 생긴다고 해도 **주문 이력 서비스가 영향을 받지 않는다**.
→ 왜냐하면 주문 이력 서비스가 각 마이크로서비스에 요청을 보낸 후에 응답을 받아서 활용하는 방식이 아니라, **독자적인 저장소를 가지고 이를 조회**하기 때문이다. 또한, 이벤트 기반을 통해 장애 전파를 막았다.
→ 이벤트를 통해 **직접적인 의존성을 줄일 수 있게 되었다.**

## 이벤트 소싱 패턴 - 쓰기 최적화

**전통적인 방법** : 변경될 row를 찾아서 해당하는 데이터의 값을 변경하고, 변경된 시점(updatedAt) 정도를 업데이트한다.

- 데이터의 상태값이 변경되면 최종으로 변경된 마지막 값을 반영한다.
- **변경 이력(history)에 대한 정보**를 알기가 어렵다.
→ 변경 이력을 저장하는 테이블을 따로 만들 수는 있지만, 그러면 이력을 저장하는 테이블이 너무 많아질 수 있다. (도메인이 늘어나고, 엔티티가 늘어남에 따라 함께 증가할 것이다.)
- 인스턴스가 많아지고 동시에 데이터 변경 요청이 들어왔을 때, **동시성 문제**나 **교착상태** 문제가 발생할 수 있다.

**[ 이벤트 스트림 저장 ]**

`이벤트 소싱` : 순차적으로 발생하는 이벤트(트랜잭션)를 모두 저장하는 방법

- 저장소와 메세지 브로커를 분리하지 않고 사용할 수 있다.
→ 메세지 브로커가 곧 저장소이고, 데이터 저장과 메세지 발행 2가지 작업을 하지 않아도 되기 때문에 성능상의 이점이 있다.
- **한번 발행된 이벤트는 불변(immutable)**이기 때문에 이벤트를 수정이나 삭제할 수 없고, **오직 이벤트 발행만** 할 수 있다. 
→ 이벤트에 대해서 **생성과 읽기만 가능**하고, 수정과 삭제를 할 수 없다.
→ 생성과 읽기만 하기 때문에 **동시성 문제나 교착상태가 발생하지 않는다**.
- 최종으로 반영된 상태가 필요하면, **발행된 이벤트를 순차적으로 계산**하여 **최종 상태 값**을 얻는다.
→ **특정 시점의 상태** 역시, 순차적으로 이벤트를 계산하여 **재현이 가능**하다.
→ 백만개의 이벤트가 있을때 최종 상태 값을 얻기 위해 매번 모든 이벤트를 계산하는 것은 매우 시간이 많이 걸리는 문제가 있을 수 있다.
- 이는 `스냅샷`을 이용하여 **특정 시점에 대한 객체의 상태값을 저장**하고 **지정한 시점 뒤의 이벤트부터만 이벤트를 순차적으로 계산**하는 방식으로 시간을 줄일 수 있다.